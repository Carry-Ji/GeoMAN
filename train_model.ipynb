{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from utils import load_data\n",
    "from utils import load_global_inputs\n",
    "from utils import basic_hyperparams\n",
    "from GeoMAN import GeoMAN\n",
    "from utils import shuffle_data\n",
    "from utils import get_batch_feed_dict\n",
    "from utils import get_valid_batch_feed_dict\n",
    "import torch.optim as optim\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'lambda_l2_reg': 0.001, 'gc_rate': 2.5, 'dropout_rate': 0.3, 'n_stacked_layers': 2, 's_attn_flag': 2, 'ext_flag': True, 'n_sensors': 35, 'n_input_encoder': 19, 'n_steps_encoder': 12, 'n_hidden_encoder': 64, 'n_input_decoder': 1, 'n_external_input': 83, 'n_steps_decoder': 6, 'n_hidden_decoder': 64, 'n_output_decoder': 1}\n"
     ]
    }
   ],
   "source": [
    "# load hyperparameters\n",
    "hps = basic_hyperparams()\n",
    "print(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 100\n",
      "eval samples: 10\n",
      "(100, 12, 19)\n",
      "(100,)\n",
      "(100,)\n",
      "(100, 6, 83)\n",
      "(100, 6)\n",
      "(500, 35)\n",
      "(500, 35, 19, 12)\n"
     ]
    }
   ],
   "source": [
    "# read data from different sets\n",
    "input_path = './sample_data/'\n",
    "training_data = load_data(\n",
    "    input_path, 'train', hps['n_steps_encoder'], hps['n_steps_decoder'])\n",
    "valid_data = load_data(\n",
    "    input_path, 'eval', hps['n_steps_encoder'], hps['n_steps_decoder'])\n",
    "global_inpts, global_attn_sts = load_global_inputs(\n",
    "    input_path, hps['n_steps_encoder'], hps['n_steps_decoder'])\n",
    "# print dataset info\n",
    "num_train = len(training_data[0])\n",
    "num_valid = len(valid_data[0])\n",
    "print('train samples: {0}'.format(num_train))\n",
    "print('eval samples: {0}'.format(num_valid))\n",
    "#[mode_local_inp, global_inp_index, global_attn_index, mode_ext_inp, mode_labels]\n",
    "print(training_data[0].shape)\n",
    "print(training_data[1].shape)\n",
    "print(training_data[2].shape)\n",
    "print(training_data[3].shape)\n",
    "print(training_data[4].shape)\n",
    "#global_inputs, global_attn_states\n",
    "print(global_inpts.shape)\n",
    "print(global_attn_sts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 0-----------\n",
      "34.392651081085205\n",
      "----------epoch 1-----------\n",
      "32.09111285209656\n",
      "----------epoch 2-----------\n",
      "30.321520805358887\n",
      "----------epoch 3-----------\n",
      "28.657651901245117\n",
      "----------epoch 4-----------\n",
      "25.779441714286804\n",
      "----------epoch 5-----------\n",
      "27.266942381858826\n",
      "----------epoch 6-----------\n",
      "25.80989384651184\n",
      "----------epoch 7-----------\n",
      "22.023674607276917\n",
      "----------epoch 8-----------\n",
      "26.35184931755066\n",
      "----------epoch 9-----------\n",
      "22.535444736480713\n",
      "----------epoch 10-----------\n",
      "19.636800527572632\n",
      "----------epoch 11-----------\n",
      "22.199295163154602\n",
      "----------epoch 12-----------\n",
      "21.164698719978333\n",
      "----------epoch 13-----------\n",
      "19.719813585281372\n",
      "----------epoch 14-----------\n",
      "23.407500863075256\n",
      "----------epoch 15-----------\n",
      "20.608052134513855\n",
      "----------epoch 16-----------\n",
      "20.279370188713074\n",
      "----------epoch 17-----------\n",
      "19.449496746063232\n",
      "----------epoch 18-----------\n",
      "19.843530893325806\n",
      "----------epoch 19-----------\n",
      "20.214853882789612\n",
      "----------epoch 20-----------\n",
      "17.229243755340576\n",
      "----------epoch 21-----------\n",
      "18.177955865859985\n",
      "----------epoch 22-----------\n",
      "19.259254813194275\n",
      "----------epoch 23-----------\n",
      "17.535050868988037\n",
      "----------epoch 24-----------\n",
      "16.7924742102623\n",
      "----------epoch 25-----------\n",
      "18.876922011375427\n",
      "----------epoch 26-----------\n",
      "17.86712336540222\n",
      "----------epoch 27-----------\n",
      "16.978861331939697\n",
      "----------epoch 28-----------\n",
      "18.208166360855103\n",
      "----------epoch 29-----------\n",
      "15.404114246368408\n",
      "----------epoch 30-----------\n",
      "16.52244544029236\n",
      "----------epoch 31-----------\n",
      "16.158969402313232\n",
      "----------epoch 32-----------\n",
      "17.401461839675903\n",
      "----------epoch 33-----------\n",
      "15.629251480102539\n",
      "----------epoch 34-----------\n",
      "15.837310194969177\n",
      "----------epoch 35-----------\n",
      "15.242109298706055\n",
      "----------epoch 36-----------\n",
      "13.94867742061615\n",
      "----------epoch 37-----------\n",
      "15.32318115234375\n",
      "----------epoch 38-----------\n",
      "14.528801202774048\n",
      "----------epoch 39-----------\n",
      "14.273948431015015\n",
      "----------epoch 40-----------\n",
      "14.607558608055115\n",
      "----------epoch 41-----------\n",
      "15.410446524620056\n",
      "----------epoch 42-----------\n",
      "14.787537574768066\n",
      "----------epoch 43-----------\n",
      "14.952339768409729\n",
      "----------epoch 44-----------\n",
      "14.370980501174927\n",
      "----------epoch 45-----------\n",
      "14.487768054008484\n",
      "----------epoch 46-----------\n",
      "14.932252168655396\n",
      "----------epoch 47-----------\n",
      "16.59219515323639\n",
      "----------epoch 48-----------\n",
      "14.920557498931885\n",
      "----------epoch 49-----------\n",
      "15.708756685256958\n",
      "===============METRIC===============\n",
      "rmse = 0.385258\n",
      "mae = 0.369622\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2017)\n",
    "model = GeoMAN(hps)\n",
    "\n",
    "total_epoch = 50\n",
    "batch_size = 16\n",
    "lr = 0.0001\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lr, momentum=0.9)\n",
    "def criterion(preds, labels):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = 0.0\n",
    "    \n",
    "    for ps, ls in zip(preds, labels):\n",
    "        loss += loss_fn(ps.float(),ls.float())\n",
    "        \n",
    "    return loss\n",
    "\n",
    "for i in range(total_epoch):\n",
    "    print('----------epoch {}-----------'.format(i))\n",
    "    training_data = shuffle_data(training_data)\n",
    "    lossSum = 0\n",
    "    i += 1\n",
    "    for j in range(0, num_train, batch_size):\n",
    "        x = get_batch_feed_dict(j, batch_size, training_data, global_inpts, global_attn_sts)\n",
    "        preds, labels = model(x)\n",
    "        loss = criterion(preds, labels)\n",
    "        lossSum += loss.data.numpy()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(lossSum)\n",
    "#print(preds, labels)\n",
    "\n",
    "# test\n",
    "n_split_test = 2\n",
    "test_loss = 0\n",
    "test_indexes = np.int64(\n",
    "    np.linspace(0, num_valid, n_split_test))\n",
    "rmses=[]\n",
    "maes=[]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for k in range(n_split_test - 1):\n",
    "    x = get_valid_batch_feed_dict(k, test_indexes, valid_data, global_inpts, global_attn_sts)\n",
    "    # re-scale predicted labels\n",
    "    batch_preds, _ = model(x)\n",
    "    batch_preds = np.array([bp.data.numpy() for bp in  batch_preds ])\n",
    "    batch_preds = np.swapaxes(batch_preds, 0, 1)\n",
    "    batch_preds = np.reshape(batch_preds, [batch_preds.shape[0], -1])\n",
    "    # re-scale real labels\n",
    "    batch_labels = valid_data[4]\n",
    "    batch_labels = batch_labels[test_indexes[k]:test_indexes[k + 1]]\n",
    "    rmses.append(np.sqrt(np.sum(np.square(batch_labels-batch_preds))/\n",
    "                         (batch_labels.shape[0]*batch_labels.shape[1])))\n",
    "    maes.append((np.abs(batch_labels-batch_preds)).mean())\n",
    "\n",
    "test_rmses = np.asarray(rmses)\n",
    "test_maes = np.asarray(maes)\n",
    "\n",
    "print('===============METRIC===============')\n",
    "print('rmse = {:.6f}'.format(test_rmses.mean()))\n",
    "print('mae = {:.6f}'.format(test_maes.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
